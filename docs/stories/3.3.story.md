# Story 3.3 – Chatbot Bridge Integration

## Status

Approved

## Story

**As a** technical evaluator or end user of the demo,
**I want** AI prompts to appear in a chatbot interface that opens automatically with context,
**so that** I can see how AI-assisted interactions would appear in a real application.

## Acceptance Criteria

From PRD Epic 3 – AI Assist Button & Chatbot Integration:

1. AC1: SDK defines `IChatbotBridge` interface; demo chatbot implements it.
2. AC2: Received prompts render in chatbot transcript with metadata.
3. AC3: Chatbot auto-expands when prompt arrives, while allowing manual close.

## Tasks / Subtasks

- [ ] Task 1 – Finalize `IChatbotBridge` interface and implementation contract (AC: 1)
  - [ ] Ensure `IChatbotBridge` is defined in shared types and exported for host apps.  
        [Source: architecture/shared-types-and-api.md#shared-types--api-contract]
  - [ ] Document expectations for `receivePrompt`, `open`, and `close` methods.

- [ ] Task 2 – Implement chatbot drawer in demo (AC: 1, 2, 3)
  - [ ] Build `ChatbotDrawer` component in `apps/demo` that implements `IChatbotBridge` via props or context.  
        [Source: architecture/overview-and-modules.md#module-boundaries]
  - [ ] Render a transcript of prompts with associated metadata (elementId, requestId, extraInfo) for each message.  
        [Source: front-end-spec.md#component-library]

- [ ] Task 3 – Wire SDK prompt events into chatbot bridge (AC: 2, 3)
  - [ ] From the SDK, emit a structured event whenever a prompt response is received and call `chatbotBridge.receivePrompt`.  
        [Source: architecture/ai-overlay.md#ai-assist-button-rendering]
  - [ ] Ensure `open()` is called to auto-expand the chatbot drawer when new prompts arrive.

- [ ] Task 4 – UX and accessibility of chatbot (AC: 2, 3)
  - [ ] Implement focus trapping, ESC to close, and proper ARIA roles for the drawer.  
        [Source: front-end-spec.md#accessibility-requirements]
  - [ ] Provide manual controls (button or shortcut) to open/close the chatbot independent of AI prompts.

- [ ] Task 5 – Logging and traceability (AC: 2)
  - [ ] Record AI prompt events in the command timeline/logging UI with references to the associated chatbot transcript entries.  
        [Source: architecture/platform-deployment.md#resilience--monitoring]
  - [ ] Ensure `requestId` is visible or accessible in debug views for cross-correlation.

## Dev Notes

### Previous Story Insights

- Builds on prompt workflow and AI button factory from Stories 3.1 and 3.2.
- This story completes the user-facing AI loop in the demo.

### Implementation Playbook (Dev Agent)

Follow these steps when implementing this story:

1. **`IChatbotBridge` type**
   - Ensure `IChatbotBridge` is defined in shared types and exported.
   - Document expectations for `receivePrompt`, `open`, and `close`.

2. **Chatbot drawer implementation**
   - Implement `ChatbotDrawer` in the demo that satisfies `IChatbotBridge` via props or context.
   - Render prompts with elementId, requestId, and extraInfo in the transcript.

3. **SDK wiring**
   - On prompt response, have the SDK call `chatbotBridge.receivePrompt` and then `open()`.
   - Ensure manual open/close controls are also available in the demo.

4. **UX & accessibility**
   - Implement focus trapping, ESC handling, and ARIA roles per the UX spec.
   - Avoid excessive animation when multiple prompts arrive.

5. **Logging and traceability**
   - Record AI prompt events in the command timeline, linked to chatbot transcript entries via `requestId`.

Dev should maintain Tasks/Subtasks and Dev Notes; QA Results remain QA’s section.

### Data Models

- Uses `AiPromptResponse` extended with `elementId` and `requestId` for transcript entries.
- Transcript items can be stored in React state within the demo.

### API Specifications

- `IChatbotBridge` functions must be called by the SDK on successful prompt fetches.

### Component Specifications

- `ChatbotDrawer` should adhere to UX spec for layout, animations, and accessibility.  
  [Source: front-end-spec.md#user-flows]
- Provide clear visual separation between prompts from different elements.

### File Locations & Structure

- Shared types: `packages/shared/src/chatbot.ts` (or similar).
- Demo component: `apps/demo/components/ChatbotDrawer.tsx`.

### Testing Requirements

- Unit tests for chatbot components where reasonable.
- Integration tests confirming end-to-end AI interaction: button click → prompt → chatbot open with transcript.

### Technical Constraints & Considerations

- Ensure that repeated prompts do not cause noisy animation or performance problems.

## Testing

- Use the demo to trigger multiple AI prompts and verify chatbot behavior, transcript, and timeline integration.

## Change Log

| Date       | Version | Description                                   | Author |
| ---------- | ------- | --------------------------------------------- | ------ |
| 2025-11-14 | 0.1.0   | Initial draft of Story 3.3 and task breakdown | SM     |

## Dev Agent Record

_This section is reserved for the Dev Agent to fill in during implementation (agent model, debug log references, completion notes, and file list)._ 

## QA Results

### QA Validation Playbook

When this story is ready for QA review:

1. **Verify Acceptance Criteria directly**
   - AC1: Confirm `IChatbotBridge` is defined and the demo’s chatbot implements it.
   - AC2: Trigger prompts and verify they appear in the chatbot transcript with metadata.
   - AC3: Confirm the chatbot auto-expands on new prompts but can still be manually closed.

2. **Accessibility and UX**
   - Check focus trapping, ESC behavior, and ARIA roles.

3. **Traceability**
   - Confirm `requestId` or equivalent is visible or easily referenced for debugging.

4. **Record QA result**
   - Summarize findings with status (READY / NEEDS REVISION / BLOCKED) and key issues.

_This section is reserved for the QA Agent to record validation results and gate decisions for this story._
